{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
    "print(f\"pytorch \\n {x}\")\n",
    "\n",
    "\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "print(f\"numpy \\n {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.FloatTensor(2, 2)\n",
    "y = torch.FloatTensor(2, 2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "z = (x + y) + torch.FloatTensor(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기를 구할 필요가 없는 연산의 경우 with 문법을 사용하여 연산을 수행한다.\n",
    "- with 문법은 컨텍스트 관리자를 사용하여 자원을 효율적으로 관리하기 위해 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(2, 2)\n",
    "y = torch.FloatTensor(2, 2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = (x + y) + torch.FloatTensor(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피드 포워드\n",
    "- 선형 계층(Linear Layer) 또는 완전연결계층(Fully-connected Layer) 구현\n",
    "- 아래의 코드는 역전파 알고리즘을통한 학습은 하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, W ,b):\n",
    "    y = torch.mm(x, W) + b\n",
    "    # mm = matrix multiplication => pytorch에서 제공하는 행렬 곱셈 연산자\n",
    "    return y\n",
    "\n",
    "x = torch.FloatTensor(16, 10)\n",
    "W = torch.FloatTensor(10, 5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module\n",
    "- nn.Module 클래스를 이용하여 사용자가 그 위에서 필요한 모델 구조를 구현할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module): # MyLinear 클래스가 nn.Module 클래스를 상속받는다.\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters()\n",
    "- 모듈 내에 선언된 학습이 필요한 파라미터들을 반환하는 iterator\n",
    "- 위의 코드로 진행하면, linear 모듈 내에는 학습 가능한 파라미터가 없다.\n",
    "    - Parameter라는 클래스를 사용하여 텐서를 감싸서 위의 문제를 해결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module): # MyLinear 클래스가 nn.Module 클래스를 상속받는다.\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyLinear, self).__init__()\n",
    "\n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "\n",
    "        return y\n",
    "    \n",
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyLinear, self).__init__() # 파이썬 2와 호환하기 위한 코드 파이썬 3에서는 다음과 같이 작성한다. super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = MyLinear(10, 5)\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역전파 수행\n",
    "- 피드포워드를 통해 얻은 값에서 실제 정답값과의 차이를 계산하여 오류(손실)를 뒤로 전달(back propagation)한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 100\n",
    "\n",
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10 ,5)\n",
    "y = linear(x)\n",
    "loss = (objective - y.sum())**2\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train(), eval()\n",
    "- nn.Module을 상속받아 구현하고 생성한 객체는 기본적으로 훈련 모드이다.\n",
    "- 이를 eval()을 사용하여 추론 모드로 바꿔주면, dropout 또는 배치 정규화(batch-normalization)와 같은 학습과 추론 시 서로 다른 forward() 동작을 하는 모듈들에 대해서도 각 상황에 따라 올바르게 동작한다.\n",
    "    - 추론이 끝나면 다시 train()을 선언하여 원래의 훈련 모드로 변경해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "linear.eval()\n",
    "# Do some inference process\n",
    "linear.train()\n",
    "# Restart training again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형회귀분석 예제\n",
    "- 임의로 생성한 텐서들을\n",
    "- 근사하고자 하는 정답 함수에 넣어 정답(y)를 구하고\n",
    "- 그 정답과 신경망을 통과한 y_hat과의 차이를 MSE를 통해 구하고\n",
    "- SGD(Stochastic Gradient Descent)를 통해 최적화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 1개의 선형 계층을 가진 MyModel 모듈 선언\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 임의의 함수 동작 구현\n",
    "def ground_truth(x):\n",
    "    return 3 * x[:, 0] + x[:, 1] - 2 * x[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델과 텐서를 입력받아 피드포워딩한 후, 역전파 알고리즘을 수행하여 경사하강법의 한 스텝을 수행한다.\n",
    "def train(model, x, y, optim):\n",
    "    # initialize gradients in all parameters in module\n",
    "    optim.zero_grad()\n",
    "\n",
    "    # feed-forward\n",
    "    y_hat = model(x)\n",
    "    # get error between answer and inferenced\n",
    "    loss = ((y - y_hat)**2).sum() / x.size(0)\n",
    "\n",
    "    # back-propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # one-step of gradient descent\n",
    "    optim.step()\n",
    "\n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-1. 앞에서 만든 함수들을 사용하기 위해 하이퍼 파라미터 설정\n",
    "batch_size = 1\n",
    "n_epochs = 1000\n",
    "n_iter = 10000\n",
    "\n",
    "model = MyModel(3, 1)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 위의 값들을 이용하여 평균 손실값이 0.001보다 작아질 때까지 훈련한다.\n",
    "for epoch in range(n_epochs):\n",
    "    ave_loss = 0\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        x = torch.rand(batch_size, 3)\n",
    "        y = ground_truth(x.data)\n",
    "\n",
    "        loss = train(model, x, y, optim)\n",
    "\n",
    "        ave_loss += loss\n",
    "    avg_loss = ave_loss / n_iter\n",
    "    \n",
    "    # simple test sample to check the network\n",
    "    x_valid = torch.FloatTensor([[.3, .2, .1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "\n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "\n",
    "    print(avg_loss, y_valid.data[0], y_hat.data[0, 0])\n",
    "\n",
    "    if avg_loss < 0.001: # finish the training if the loss is smaller than 0.001\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that tensor is declared in torch.cuda.\n",
    "x = torch.cuda.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "# .cuda() let module move to GPU memory\n",
    "linear.cuda()\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
