{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀식은 nn.Linear()가 하나 있는 모델이다.\n",
    "# nn.Linear()을 줄지어 여러층으로 구성된 신경망을 만들면 이를 다층 신경망 이라고 한다.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error # 회귀 문제의 평가를 위해 MSE 철도를 불러온 후 제곱근을 씌워 RMSE를 사용한다\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Pytorch_sample/data/reg.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Price\", axis=1).to_numpy() # Price를 제외한 나머지를 변수로 사용한다.\n",
    "Y = df[\"Price\"].to_numpy().reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 데이터 만들기\n",
    "class TensorData(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "trainsets = TensorData(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=32, shuffle=True)\n",
    "testsets = TensorData(X_test, Y_test)\n",
    "testloader = torch.utils.data.DataLoader(testsets, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축하기\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(13, 50, bias = True)\n",
    "        self.fc2 = nn.Linear(50, 30, bias = True)\n",
    "        self.fc3 = nn.Linear(30, 1, bias = True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-7)\n",
    "# Adam은 최적화 방법을 정의한다. weight_decay는 L2정규화에서의 penalty 값을 의미하며, 값이 클수록 제약조건이 강함을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트\n",
    "n = len(trainloader) # 매 에포크 손실 함수값의 평균을 구하기 위해 배치 반복 수를 n이라고 한다.\n",
    "for epoch in range(400):\n",
    "    running_loss = 0.0 # 매 에포크 손실 함수값의 평균을 구하기 위해 초기값을 0으로 설정한다.\n",
    "    for data in trainloader:\n",
    "        inputs, values = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, values)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() # 매 에포크 손실 함수값의 평균을 구하기 위해 running_loss에 배치마다 로스를 더한다.\n",
    "\n",
    "    loss_.append(running_loss / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 그리기\n",
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluation(dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.float)\n",
    "    actual = torch.tensor([], dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs, values = data\n",
    "            outputs = model(inputs)\n",
    "            predictions = torch.cat((predictions, outputs), 0)\n",
    "            actual = torch.cat((actual, values), 0)\n",
    "            # torch.cat에서 0이라는 것은 0번째 차원을 기준으로 누적한다는 의미이다.\n",
    "            # 즉, 10x2와 10x2인 두 텐서가 있을 때, cat의 기준이 0이면, 20x2가 되고 1이면 10x4가된다.\n",
    "    predictions = predictions.numpy()\n",
    "    actual = actual.numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n",
    "test_rmse = evaluation(testloader) # 시험 데이터의 RMSE\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE : {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과와 테스트 결과의 차이가 너무 크다.\n",
    "# 즉, 학습 데이터에 과적합이 되어 있다고 판단할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
