{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "타이타닉 탑승자 데이터\n",
    "- PassengerId \n",
    "    - 탑승자 데이터 일련 번호\n",
    "- Survived\n",
    "    - 생존 여부 \n",
    "        0 : 사망\n",
    "        1 : 생존\n",
    "- Pclass\n",
    "    - 티켓의 선실 등급\n",
    "        - 1 : 일등석\n",
    "        - 2 : 이등석\n",
    "        - 3 : 삼등석\n",
    "- Name\n",
    "    - 탑승자 이름\n",
    "- Sex\n",
    "    - 탑승자 성별\n",
    "- Age\n",
    "    - 탑승자 나이\n",
    "- SibSp\n",
    "    - 같이 탑승한 형제자매 또는 배우자 인원 수\n",
    "- Parch\n",
    "    - 같이 탑승한 부모 또는 어린이 인원 수\n",
    "- Ticket\n",
    "    - 티켓 번호\n",
    "- Fare\n",
    "    - 요금\n",
    "- Cabin\n",
    "    - 선실 번호\n",
    "- Embarked\n",
    "    - 중간 정착 항구\n",
    "        - C : Cherbourg\n",
    "        - Q : Queenstown\n",
    "        - S : Southampton\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv(\"D:/대학원/머신러닝 특론/타이타닉 생존자 데이터셋/train.csv\")\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df.info())\n",
    "'''\n",
    "891 non-null -> 891개의 데이터가 Null이 아니다.\n",
    "Age\n",
    "- 714 non-null -> 714개의 데이터가 Null이 아니다. 즉, Null인 데이터가 존재한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Age는 평균 나이, Cabin과 Embardked는 N으로 Null을 변경한다.\n",
    "'''\n",
    "titanic_df[\"Age\"].fillna(titanic_df[\"Age\"].mean(), inplace=True)\n",
    "titanic_df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "titanic_df[\"Embarked\"].fillna(\"N\", inplace=True)\n",
    "print(titanic_df.isnull().sum()) # Null이 없어진 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sex, Cabin, Embarked의 값 분포 확인\n",
    "'''\n",
    "print(titanic_df[\"Sex\"].value_counts())\n",
    "print(titanic_df[\"Cabin\"].value_counts())\n",
    "print(titanic_df[\"Embarked\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cabin의 앞글자만 가져와서 구분한다.\n",
    "'''\n",
    "titanic_df[\"Cabin\"] = titanic_df[\"Cabin\"].str[:1] # Cabin의 첫글자(앞글자)만 가져온다.\n",
    "print(titanic_df[\"Cabin\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby([\"Sex\", \"Survived\"])[\"Survived\"].count()\n",
    "'''\n",
    "여성 생존율 = 233 / (233 + 81 = 314) => 74.2%\n",
    "남성 생존율 = 109 / (468 + 109 = 577) => 18.9%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# 성별에 따른 생존율 시각화\n",
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객실 등급과 성별에 따른 생존율\n",
    "sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=titanic_df)\n",
    "\n",
    "'''\n",
    "hue\n",
    "- hue 매개변수는 데이터를 여러 그룹으로 나누어 각 그룹에 대한 정보를 다른 색상에 바로 표시할 때 사용한다.\n",
    "- 위의 코드를 예로 들면, Pclass에 대하여 남성과 여성의 생존율을 표시한다.\n",
    "- 즉, hue는 데이터의 카테고리를 구분하는 데 사용되며, 이를 통해 같은 x 값에 대한 여러 y값들을 각각 다른 색상으로 표시할 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이에 따른 생존율\n",
    "def get_category(age):\n",
    "    cat = \"\"\n",
    "    if age <= -1: cat=\"Unknown\"\n",
    "    elif age <= 5: cat = \"Baby\"\n",
    "    elif age <= 12: cat = \"Child\"\n",
    "    elif age <= 18: cat = \"Teenager\"\n",
    "    elif age <= 25: cat = \"Student\"\n",
    "    elif age <= 35: cat = \"Young Adult\"\n",
    "    elif age <= 60: cat = \"Adult\"\n",
    "    else: cat = \"Elderly\"\n",
    "    return cat\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "groups_name = [\"Unknown\", \"Baby\", \"Child\", \"Teenager\", \"Student\", \"Young Adult\", \"Adult\", \"Elderly\"]\n",
    "\n",
    "titanic_df[\"Age_cat\"] = titanic_df[\"Age\"].apply(lambda x:get_category(x))\n",
    "sns.barplot(x=\"Age_cat\", y=\"Survived\", hue=\"Sex\", data=titanic_df, order=groups_name)\n",
    "titanic_df.drop(\"Age_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_feature(df):\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "titanic_df = encode_feature(titanic_df)\n",
    "titanic_df.head()\n",
    "'''\n",
    "LabelEncoder\n",
    "- sklearn.preprocessing 모듈에 있는 클래스이다.\n",
    "- 카테고리형 레이블을 정수형으로 변환하는데 사용된다.\n",
    "\n",
    "features 리스트에 인코딩할 특성들의 이름을 지정한다.\n",
    "\n",
    "for문을 돌려 LabelEncoder 객체 le를 생성하고, fit 메서드를 사용하여 특성의 모든 유니크한 값을 학습한다.\n",
    "그 후, transform 메서드를 사용하여 각 레이블을 정수로 변환한다. 변환된 값은 원래의 데이터프레임에 다시 저장된다.\n",
    "\n",
    "encode_feature()를 호출하여 titanic_df 데이터프레임의 특성들을 인코딩한다.\n",
    "- Cabin, Sex, Embarked가 정수형으로 변경된 것을 확인할 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 구현\n",
    "def fillna(df):\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace = True)\n",
    "    df[\"Cabin\"].fillna(\"N\", inplace = True)\n",
    "    df[\"Embarked\"].fillna(\"N\", inplace = True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace = True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "titanic_df = pd.read_csv(\"D:/대학원/머신러닝 특론/타이타닉 생존자 데이터셋/train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "X_titanic_df = titanic_df.drop(\"Survived\", axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, dt_pred))\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, rf_pred))\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(iter_count, accuracy)\n",
    "    \n",
    "    print(np.mean(scores))\n",
    "\n",
    "exec_kfold(dt_clf, folds=5)\n",
    "'''\n",
    "enumerate() 함수는 반복 가능한 객체(리스트, 튜플 문자열)을 인자로 받아, 인덱스와 해당 인덱스의 값을 반복하는 반복자(iterator)를 생성한다.\n",
    "이 함수는 주로 반복문에서 사용되며, 반복문을 통해 객체의 각 요소에 접근할 때 해당 요소의 인덱스도 함께 얻을 수 있게 한다.\n",
    "- 즉, 반복문에서 현재의 인덱스와 값을 동시에 얻을 수 있다.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cross_val_score\n",
    "- 위의 교차 검증 과정을 하나의 함수만들어 사용한다.\n",
    "'''\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print(iter_count, accuracy)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\" : [2, 3, 5, 10],\n",
    "    \"min_samples_split\" : [2, 3, 5],\n",
    "    \"min_samples_leaf\" : [1, 5, 8]\n",
    "}\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid = parameters, scoring=\"accuracy\", cv=5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_dclf.best_params_)\n",
    "print(grid_dclf.best_score_)\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print(accuracy)\n",
    "\n",
    "'''\n",
    "parameters = {\n",
    "    \"max_depth\" : [2, 3, 5, 10],\n",
    "    \"min_samples_split\" : [2, 3, 5],\n",
    "    \"min_samples_leaf\" : [1, 5, 8]\n",
    "}\n",
    "- GridSearchCV에서 사용할 하이퍼파라미터의 값들을 딕셔너리 형태로 정의한다.\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid = parameters, scoring=\"accuracy\", cv=5)\n",
    "- GridSearchCV 객체를 생성한다.\n",
    "    - dt_clf는 탐색할 결정 트리 모델이다.\n",
    "    - param_grid는 탐색할 하이퍼파라미터의 그리드이다.\n",
    "    - scoring은 모델 평가 기준이다.\n",
    "    - cv는 교차 검증 폴드 수이다.\n",
    "\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "- GridSerachCV를 사용하여 모델을 학습시킨다.\n",
    "- 이 과정에서 모든 하이퍼파라미터 조합에 대해 교차 검증이 수행되며, 최적의 하이퍼파라미터가 선택된다.\n",
    "\n",
    "print(grid_dclf.best_params_)\n",
    "print(grid_dclf.best_score_)\n",
    "- 최적의 하이퍼파라미터와 해당 하이퍼파라미터에서의 평균 교차 검증 점수를 출력한다.\n",
    "\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "- 최적의 하이퍼파라미터로 학습된 모델을 추출한다.\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print(accuracy)\n",
    "- 최적의 모델을 사용하여 테스트 데이터셋에 대한 예측을 수행하고, 정확도를 계산하여 출력한다.\n",
    "\n",
    "이런 과정을 거쳐, GridSearchCV를 통해 결정 트리 모델의 최적의 하이퍼파라미터를 찾고, 이를 사용하여 모델을 학습하고 평가하는 전체 과정을 수행할 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "평가\n",
    "\n",
    "정확도(Accuracy)\n",
    "- 실제 데이터에서 예측 데이터가 얼마나 같은지 판단하는 지표이다.\n",
    "    - 정확도 = 예측 결과가 실제와 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "- 이진 분류의 경우 데이터 구성에 따라 머신 러닝 모델의 성능을 왜곡할 수 있다.\n",
    "'''\n",
    "\n",
    "# 왜곡의 예\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "def fillna(df):\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace = True)\n",
    "    df[\"Cabin\"].fillna(\"N\", inplace = True)\n",
    "    df[\"Embarked\"].fillna(\"N\", inplace = True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace = True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Cabin\", \"Sex\", \"Embarked\"]\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X[\"Sex\"].iloc[i] == 1: pred[i] = 0\n",
    "            else: pred[i] = 1\n",
    "        return pred\n",
    "    '''\n",
    "    클래스의 인스턴스 메서드에서\n",
    "    self를 명시적으로 넣어주지 않으면, 메서드 내에서 현재 인스턴스에 접근할 수 없게 된다.\n",
    "    즉, 인스턴스 변수를 사용하거나 다른 인스턴스에서 메서드를 호출할 수 없게 된다.\n",
    "    '''\n",
    "\n",
    "titanic_df = pd.read_csv(\"D:/대학원/머신러닝 특론/타이타닉 생존자 데이터셋/train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "X_titanic_df = titanic_df.drop(\"Survived\", axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print(accuracy_score(y_test, mypredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "앞의 예시에서 단순히 Sex가 1이면 죽음(0), 아니면 생존(1)로 처리하여도\n",
    "정확도가 0.7 ~ .8의 높은 값을 얻는다.\n",
    "\n",
    "레이블 값 분포가 불균형한 경우 적합한 평가가 아니다.\n",
    "- 100개의 데이터 중 90개는 레이블이 0, 10개는 1인 경우\n",
    "    - 예측 결과를 무조건 0으로 반환해도 정확도가 90%가 나온다.\n",
    "\n",
    "왜곡의 예\n",
    "- MNIST 데이터 중 레이블 7만 True, 나머지는 False\n",
    "- 이진 분류 문제로 변경\n",
    "- 전체 데이터의 10%는 True, 90%는 False\n",
    "    - 예측 값을 무조건 0으로 반환해도 정확도가 90%이다.\n",
    "'''\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    def predict(self ,X):\n",
    "        return np.zeros((X.shape[0], 1), dtype=int)\n",
    "\n",
    "digits = load_digits()\n",
    "y = (digits.target == 7).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y)\n",
    "print(y_test.shape)\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "clf = MyFakeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "오차 행렬(Confusion Matrix)\n",
    "- 예측 오류가 얼마인지와 어떤 유형의 예측 오류가 발생하는지 나타낸다.\n",
    "- TN(True Negative)\n",
    "    - Negative로 예측했는데 그게 맞는 경우\n",
    "- FP(False Positive)\n",
    "    - Positive로 예측했는데 그게 틀린 경우\n",
    "- FN(False Negative)\n",
    "    - Negative로 예측했는데 그게 틀린 경우\n",
    "    - 즉, 원래 데이터는 참인경우\n",
    "- TP(True Positive)\n",
    "    - Positive로 예측했는데 그게 맞는 경우\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "'''\n",
    "정확도 = 예측 결과가 실제와 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "=  TN + TP / TN + FP + FN + TP\n",
    "\n",
    "\n",
    "\n",
    "재현율 = TP / FN + TP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정밀도(Precision)\n",
    "- TP / FP + TP\n",
    "- Positive로 예측한 것 중 맞게 예측한 것의 비율\n",
    "- 양성 예측도(Positive 예측 성능을 더욱 정밀하게 측정)라고도 한다.\n",
    "- 실제로는 Negative인데 Positive로 잘못 판단하면 큰일 나는 경우에 적용한다.\n",
    "- 예) 스팸 메일 판단 모델\n",
    "    - Positive를 Negative로 판단하면 불편함 정도\n",
    "    - Negative를 Positive로 판단하면 업무 차질\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "재현율(Recall)\n",
    "- TP / FN + TP\n",
    "- 정답이 Positive인 것 중 맞게 예측한 것의 비율\n",
    "- 민감도(Sensitivity), TPR(True Positive Rate)라고도 한다.\n",
    "- 실제로는 Positive인데 Negative로 잘못 판단하면 큰일 나는 경우에 적용한다.\n",
    "- 예) 암 판단 모델\n",
    "    - Positive를 Negative로 판단하면 생명에 지장\n",
    "    - Negative를 Positive로 판단하면 재검사 시도\n",
    "- 예) 금융 사기 적발 모델\n",
    "    - Positive를 Negative로 판단하면 회사에 손해\n",
    "    - Negative를 Positive로 판단하면 재검사 시도\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정밀도 vs 재현율\n",
    "- 정밀도 = TP / FP + TP\n",
    "- 재현율 = TP / FN + TP\n",
    "\n",
    "- 분자는 같다.\n",
    "- 정밀도는 FP를 낮추는데 초점을 둔다.\n",
    "- 재현율은 FN을 낮추는데 초점을 둔다.\n",
    "\n",
    "- 정밀도와 재현율 모두 높은 것이 좋다.\n",
    "- 둘 중 하나만 높고 다른 하나는 낮으면 안좋다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"D:/대학원/머신러닝 특론/타이타닉 생존자 데이터셋/train.csv\")\n",
    "\n",
    "df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis = 1, inplace = True)\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace = True)\n",
    "df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "df[\"Embarked\"].fillna(\"N\", inplace = True)\n",
    "df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df[\"Cabin\"] = encoder.fit_transform(df[\"Cabin\"])\n",
    "df[\"Sex\"] = encoder.fit_transform(df[\"Sex\"])\n",
    "df[\"Embarked\"] = encoder.fit_transform(df[\"Embarked\"])\n",
    "\n",
    "y = df[\"Survived\"]\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver = \"liblinear\")\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(accuracy_score(y_test, y_hat))\n",
    "print(precision_score(y_test, y_hat))\n",
    "print(recall_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "트레이드오프(Trade-off)\n",
    "- 정밀도 / 재현율이 강조되어야 하는 경우\n",
    "    - 분류의 임곗값을 조정하면 바뀔 수 있다.\n",
    "- 한쪽을 높이면 다른 쪽이 떨어질 수 있다.\n",
    "- predict_proba()\n",
    "    - 테스트 데이터에 대해 예측 확률 반환\n",
    "'''\n",
    "proba = lr.predict_proba(X_test)\n",
    "result = np.concatenate([proba, y_hat.reshape(-1, 1)], axis=1)\n",
    "print(result)\n",
    "# 0일 확률과 1일 확률 중 더 높은 것을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Binarizer 클래스\n",
    "- fit_transform():\n",
    "    - 지정된 문턱 값보다 크면 1, 아니면 0으로 변환한다.\n",
    "'''\n",
    "from sklearn.preprocessing import Binarizer\n",
    "tmp = [[1, -1, 2],\n",
    "       [2, 0, 0],\n",
    "       [0, 1.1, 1.2]]\n",
    "binarizer = Binarizer(threshold=1.1) # tmp값이 threshold값 보다 크면 1 아니면 0으로 반환한다.\n",
    "print(binarizer.fit_transform(tmp))\n",
    "'''\n",
    "[[0. 0. 1.]\n",
    " [1. 0. 0.]\n",
    " [0. 0. 1.]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = proba[:, 1].reshape(-1, 1) # pr = proba에서 모든 행을 가져오고, 1번째 열만 가져온다.\n",
    "\n",
    "y_hat = Binarizer(threshold=0.5).fit_transform(pr) # pr이 0.5보다 크면 1 아니면 0으로 반환한다.\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(accuracy_score(y_test, y_hat))\n",
    "print(precision_score(y_test, y_hat))\n",
    "print(recall_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in [0.4, 0.45, 0.5, 0.55, 0.6]:\n",
    "    y_hat = Binarizer(threshold=th).fit_transform(pr)\n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    print(accuracy_score(y_test, y_hat))\n",
    "    print(precision_score(y_test, y_hat))\n",
    "    print(recall_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, ths = precision_recall_curve(y_test, pr)\n",
    "\n",
    "N = ths.shape[0]\n",
    "index = np.arange(0, N, 15)\n",
    "print(index)\n",
    "\n",
    "print(ths[index])\n",
    "print(precisions[index])\n",
    "print(recalls[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = ths.shape[0]\n",
    "plt.plot(ths, precisions[:N], \"--\")\n",
    "plt.plot(ths, recalls[:N])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정밀도(Precision)와 재현율(Recall)의 맹점\n",
    "- 환자 1000명 중 확실한 Positive 징후 환자 1명만 Positive, 나머지는 Negative로 예측한다.\n",
    "    - TP = 1, FP = 0 => 정밀도 100%\n",
    "\n",
    "- 모든 환자를 Positive로 예측, 실제 양성은 30명\n",
    "    - FN = 0, TP = 30 => 재현율 100%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "F1 스코어\n",
    "- 정밀도와 재현율 결합\n",
    "- F1 = 2 / ((1 / recall) = (1 / precision)) = 2 * (precision * recall) / (precision + recall)\n",
    "    - 정밀도 0.9, 재현율 0.1 => F1 = 0.18\n",
    "    - 정밀도 0.5, 재현율 0.5 => F1 = 0.5\n",
    "'''\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for th in [0.4, 0.45, 0.5, 0.55, 0.6]:\n",
    "    y_hat = Binarizer(threshold=th).fit_transform(pr)\n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    print(accuracy_score(y_test, y_hat))\n",
    "    print(precision_score(y_test, y_hat))\n",
    "    print(recall_score(y_test, y_hat))\n",
    "    print(f1_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ROC 곡선(Reciver Operation Characteristic Curve)\n",
    "- FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지 나타내는 곡선이다.\n",
    "- X축 : FPR\n",
    "    - False Positive / Total Number of Actual Negative Events\n",
    "    - 실제로 N인데 P로 분류한 비율\n",
    "- Y축 : TPR\n",
    "    - True Positive / Total Number of Actual Positive Events\n",
    "    - 실제로 P인데 P로 분류한 비율\n",
    "'''\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fprs, tprs, ths = roc_curve(y_test, pr)\n",
    "plt.plot(fprs, tprs)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# 가운데 점선에 가까울수록 성능이 떨어진다.\n",
    "'''\n",
    "AUC(Area Under Curve)\n",
    "- ROC 곡선의 아래의 면적이다.\n",
    "    - 1에 가까울 수록 좋다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for th in [0.4, 0.45, 0.5, 0.55, 0.6]:\n",
    "    y_hat = Binarizer(threshold=th).fit_transform(pr)\n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    print(accuracy_score(y_test, y_hat))\n",
    "    print(precision_score(y_test, y_hat))\n",
    "    print(recall_score(y_test, y_hat))\n",
    "    print(f1_score(y_test, y_hat))\n",
    "    print(roc_auc_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(accuracy_score(y_test, y_hat))\n",
    "print(precision_score(y_test, y_hat))\n",
    "print(recall_score(y_test, y_hat))\n",
    "print(f1_score(y_test, y_hat))\n",
    "print(roc_auc_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "피마 인디언 당뇨병 분류\n",
    "- Pregnancies\n",
    "    - 임신 횟수\n",
    "- Glucose\n",
    "    - 포도당 부하 검사 수치\n",
    "- BloodPressure\n",
    "    - 혈압\n",
    "- SkinThickness\n",
    "    - 팔 삼두근 뒤쪽의 피하지방 측정값\n",
    "- Insulin\n",
    "    - 혈청 인슐린\n",
    "- BMI\n",
    "    - 체질량지수\n",
    "- DiabetesPedigreeFunction\n",
    "    - 당뇨 내력 가중치 값\n",
    "- Age\n",
    "    - 나이\n",
    "- Outcome\n",
    "    - 클래스 결정 값(0 또는 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"D:/대학원/머신러닝 특론/피마 인디언 당뇨병 분류/diabetes.csv\")\n",
    "print(diabetes[\"Outcome\"].value_counts())\n",
    "# 당뇨병 500명, 당뇨 x 268명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.iloc[:, :-1] # Outcome 열 제외\n",
    "y = diabetes.iloc[:, -1] # Outcome 열만 사용\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "lr = LogisticRegression(solver = \"liblinear\")\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(accuracy_score(y_test, y_hat))\n",
    "print(precision_score(y_test, y_hat))\n",
    "print(recall_score(y_test, y_hat))\n",
    "print(f1_score(y_test, y_hat))\n",
    "print(roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, ths = precision_recall_curve(y_test, y_prob)\n",
    "N = ths.shape[0]\n",
    "plt.plot(ths, precisions[:N], \"--\")\n",
    "plt.plot(ths, recalls[:N])\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.describe() # min 값이 0인 피처가 많다. => 이상치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diabetes[\"Glucose\"], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min 값이 0인 피처 추출\n",
    "# - 0의 건수\n",
    "# 전체 데이터 건수 대비 비율\n",
    "zero_features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "total_count = diabetes[\"Glucose\"].count()\n",
    "\n",
    "for feature in zero_features:\n",
    "    zero_count = diabetes[diabetes[feature] == 0][feature].count()\n",
    "    print(feature, zero_count, 100 * zero_count / total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0값을 평균 값으로 대체\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mean_zero_features = diabetes[zero_features].mean()\n",
    "diabetes[zero_features] = diabetes[zero_features].replace(0, mean_zero_features)\n",
    "\n",
    "X = diabetes.iloc[:, :-1]\n",
    "y = diabetes.iloc[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(accuracy_score(y_test, y_hat))\n",
    "print(precision_score(y_test, y_hat))\n",
    "print(recall_score(y_test, y_hat))\n",
    "print(f1_score(y_test, y_hat))\n",
    "print(roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 조정\n",
    "for th in [0.3, 0.33, 0.36, 0.39, 0.42, 0.45, 0.48, 0.5]:\n",
    "    y_hat = Binarizer(threshold=th).fit_transform(y_prob.reshape(-1, 1))\n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    print(accuracy_score(y_test, y_hat))\n",
    "    print(precision_score(y_test, y_hat))\n",
    "    print(recall_score(y_test, y_hat))\n",
    "    print(f1_score(y_test, y_hat))\n",
    "    print(roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
