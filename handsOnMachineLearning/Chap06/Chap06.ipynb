{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # 꽃잎의 길이와 너비\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 가지분할을 최대 3번까지 허용해서 만들어진 모델의 훈련샘플들에 대한 예측 결과이다.\n",
    "- 1차: 꽃잎 길이 = 2.45\n",
    "- 2차: 꽃잎 너비 = 1.75\n",
    "- 3차: (우상단) 꽃잎 길이=4.85, (우하단) 꽃잎 길이 = 4.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)        # 1차 분할 기준선\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)  # 2차 분할 기준선\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)     # 3차 분할 기준선 (우하단)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)     # 3차 분할 기준선 (우상단)\n",
    "\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규제 매개변수\n",
    "\n",
    "결정트리 모델의 규제는 기본적으로 분할을 제한하는 방식으로 이뤄진다.\n",
    "아래 코드는 min_sample_leaf=4 규제를 사용하는 모델(아래 그림 오른편)과 어느 규제도 사용하지 않은 모델(아래 그림 왼편)의 차이를 보여준다.\n",
    "사용되는 훈련세트는 moons 데이터셋이다.\n",
    "- 왼쪽 결정트리\n",
    "    - 과대적합 발생\n",
    "- 오른쪽 결정트리\n",
    "    - min_samples_leaf=4 규제 사용.\n",
    "    - 즉, 리프노드에 최소 4개 이상의 샘플이 포함되어 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
    "\n",
    "deep_tree_clf1 = DecisionTreeClassifier(random_state=42) # 규제 x\n",
    "deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4,random_state=42) # 규제 사용\n",
    "deep_tree_clf1.fit(Xm, ym)\n",
    "deep_tree_clf2.fit(Xm, ym)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
    "plt.title(\"No restrictions\", fontsize=16)\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
    "plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀\n",
    "\n",
    "결정트리 회귀모델 알고리즘은 분류모델과 거의 동일한 알고리즘을 사용한다.\n",
    "아래 코드는 2차 다항식을 이용하여 생성된 훈련 세트에 대한 결정트리 회귀모델 훈련을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 다항식 훈련세트 + 잡음\n",
    "np.random.seed(42)\n",
    "\n",
    "m=200\n",
    "X=np.random.rand(m, 1)\n",
    "y = 4*(X-0.5)**2\n",
    "y = y+np.random.randn(m, 1) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 max_depth를 2또는 3으로 지정하고 결정트리 회귀모델을 훈련시킨 결과를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 함수는 훈련 세트와 노드별 예측값(빨강 직선)을 그린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel=\"$y$\"):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
    "    y_pred = tree_reg.predict(x1)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel, fontsize=18, rotation=0)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왼쪽: max_depth=2\n",
    "오른쪽: max_depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# 왼쪽 그림\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg1, X, y)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "plt.text(0.21, 0.65, \"Depth=0\", fontsize=15)\n",
    "plt.text(0.01, 0.2, \"Depth=1\", fontsize=13)\n",
    "plt.text(0.65, 0.8, \"Depth=1\", fontsize=13)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"max_depth=2\", fontsize=14)\n",
    "\n",
    "# 오른쪽 그림\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
    "    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth=1)\n",
    "plt.text(0.3, 0.5, \"Depth=2\", fontsize=13)\n",
    "plt.title(\"max_depth=3\", fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀모델 규제\n",
    "\n",
    "결정트리 회귀모델의 규제는 CART 알고리즘이 노드 분할에 사용하는 기준 하이퍼파라미터에 사용되는 값을 제외하고 분류모델의 경우와 완전히 동일하다.\n",
    "- 분류모델의 비용함수 기준: 지니 불순도 또는 엔트로피\n",
    "- 회귀모델의 비용함수 기준: MSE, MAE 등\n",
    "\n",
    "아래 코드는 min_samples_leaf=10 규제를 사용하는 회귀모델(아래 그림 오른편)과 어느 규제도 사용하지 않은 회귀모델(아래 그림 왼편)의 차이를 보여준다.\n",
    "- 왼편 결정트리: 과대적합 발생\n",
    "- 오른편 결정트리: min_samples_leaf=10 규제 사용\n",
    "    - 즉, 리프노드에 최소 10개 이상의 샘플이 포함되어 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "x1 = np.linspace(0, 1, 1500).reshape(-1, 1)\n",
    "y_pred1=tree_reg1.predict(x1)\n",
    "y_pred2=tree_reg2.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# 왼편 그림\n",
    "plt.sca(axes[0])\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"No restrictions\", fontsize=14)\n",
    "\n",
    "# 오른편 그림\n",
    "plt.sca(axes[1])\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.title(\"min_samples_leaf={}\".format(tree_reg2.min_samples_leaf), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불안정성\n",
    "\n",
    "결정트리 모델의 훈련과 사용은 매우 쉽고, 성능도 강력하다.\n",
    "하지만, 축(axis)에 수직인결정경계ㅒ만사용하기에, 회전, 샘플 삭제 or 추가 등 훈련세트의 작은 변화에도 민감하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 결정트리 모델의 회전 민감도를 보여준다.\n",
    "2개의 특성을 가지며, 임의로 생성된 100개의 훈련 샘플을 시계방향으로 45도 회전시킨 후, 훈련시킨 모델의 결정경계가 직선에서 계단식으로 변화되는것을볼 수 있다.\n",
    "즉, 일반화성능이 보다 약한 모델이 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "\n",
    "Xs=np.random.rand(100, 2) - 0.5\n",
    "ys = (Xs[:, 0] > 0).astype(np.float32) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계방향으로 45도 회전\n",
    "angle = np.pi / 4\n",
    "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
    "Xsr = Xs.dot(rotation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정트리 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왼쪽 그래프 모델\n",
    "tree_clf_s = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_s.fit(Xs, ys)\n",
    "\n",
    "# 오른쪽 그래프 모델\n",
    "tree_clf_sr = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_sr.fit(Xsr, ys)\n",
    "\n",
    "# 그래프 그리기\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey = True)\n",
    "\n",
    "# 왼쪽 그래프\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(tree_clf_s, Xs, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
    "\n",
    "# 오른쪽 그래프\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(tree_clf_sr, Xsr, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "민감도 예제 2\n",
    "\n",
    "IRIS 데이터를 시계 방향으로 20도 회전한 후, 훈련시키면 분류 모델의 결정경계가 이전과 많이 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # 꽃잎의 길이와 너비\n",
    "y = iris.target\n",
    "\n",
    "# 시계방향으로 20도 회전\n",
    "angle = np.pi / 180 * 20\n",
    "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
    "Xr = X.dot(rotation_matrix)\n",
    "\n",
    "tree_clf_r = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_r.fit(Xr, y)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plot_decision_boundary(tree_clf_r, Xr, y, axes=[0.5, 7.5, -1.0, 1], iris=False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 민감도 예제\n",
    "\n",
    "훈련세트에 포함된 버시컬러 품종 중 가장 넓은 꽃잎을 가진 샘플을 삭제한 후, 훈련시킨 결정트리 분류모델의 결정경계를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[(X[:, 1]==X[:, 1][y==1].max()) & (y==1)] # 가장 넓은 꽃잎을 갖는 버시컬러 샘플의 특성 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 넓은 버시컬러 샘플 제거 후 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_widest_versicolor = (X[:, 1]!=1.8) | (y==2)  # y==2는 버지니카 품종은 그대로 둠.\n",
    "\n",
    "X_tweaked = X[not_widest_versicolor]\n",
    "y_tweaked = y[not_widest_versicolor]\n",
    "\n",
    "tree_clf_tweaked = DecisionTreeClassifier(max_depth=2, random_state=40)\n",
    "tree_clf_tweaked.fit(X_tweaked, y_tweaked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정경계를 기준값으로, 꽃잎의 길이는 전혀 사용되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf_tweaked, X_tweaked, y_tweaked, legend=False)\n",
    "plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth=2)\n",
    "plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.text(1.0, 0.9, \"Depth=0\", fontsize=15)\n",
    "plt.text(1.0, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
