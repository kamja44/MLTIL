{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드(Sigmoid)와 하이퍼볼릭 탄젠트(Hyperbolic Tangent)는 대표적인 활성화 함수(activation Function)이다.\n",
    "# 시그모이드(sigmoid)는 음의 무한대에 가까울수록 0에 근접하는 값을 가지며, 양의 무한대에 가까울수록 1에 근접하는 값을 갖는다.\n",
    "# 즉, 시그모이드 함수의 출력값의 범위는 0에서 1사이로 정해져 있다.\n",
    "# 하이퍼볼릭 탄젠트(탄에이치)는 음의 무한대에 가까울수록 -1에 근접하는 값을 가지며, 양의 무한대에 가까울수록 1에 근접하는 값을 갖는다.\n",
    "# 즉, 탄에이치 함수의 출력값의 범위는 -1에서 1사이이다.\n",
    "# 두 함수 모두 양 극단의 기울기는 0에 근접하는 것을 특징으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 수식\n",
    "$$\n",
    "\\sigma(x)=\\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "하이퍼볼릭 탄젠트 수식\n",
    "$$\n",
    "\\text{tanh}(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀의 경우, 키와 몸무게 같은 선형 데이터의 관계를 학습하는 문제이다.\n",
    "# 즉, n차원의 실수 벡터를 입력으로 받아 선형 관계의 m차원의 실수 벡터를 반환하도록 학습하는 문제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)\n",
    "# 위스콘신 유방암 데이터셋은 30개의 속성을 가지며, 이를 통해 유방암 여부를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스로 데이터를 변환한다.\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df[\"class\"] = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[[\"class\"] + list(df.columns[:10])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨 윗 줄의 경우 각 속성별 샘플의 점들이 0번 클래스에 해당하는 경우 아래쪽에, 1번 클래스에 해당하는 경우 위쪽에 찍혀 있는 것을 볼 수 있다.\n",
    "# 이 점들의 클래스별 그룹이 특정 값을 기준으로 명확히 나눠진다면 좋다는 것을 확인할 수 있다.\n",
    "# 마찬가지로 다른 속성들에 대해서도 페어 플롯을 그린다.\n",
    "\n",
    "sns.pairplot(df[[\"class\"] + list(df.columns[10:20])])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[[\"class\"] + list(df.columns[20:30])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 그림들을 바탕으로 몇 개를 골라서 좀 더 예쁘게 표현한다.\n",
    "\n",
    "cols = [\"mean radius\", \"mean texture\",\n",
    "        \"mean smoothness\", \"mean compactness\", \"mean concave points\",\n",
    "        \"worst radius\", \"worst texture\",\n",
    "        \"worst smoothness\", \"worst compactness\", \"worst concave points\",\n",
    "        \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols[:-1]:\n",
    "    sns.histplot(df, x=c, hue=cols[-1], bins=50, stat='probability')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스에 따른 속성별 분포를 나타낸 것이다.\n",
    "# 0번 클래스에는 파란색, 1번 클래스는 주황색으로 표시되어 있다.\n",
    "# 겹치는 영역이 적을수록 좋은 속성이라고 판단할 수 있다.\n",
    "# 완벽하게 두 클래스를 나눠주는 속성은 없지만, 부족한 부분은 다른 속성으로 보완할 수 있을 것이라 생각하고, 해당 속성들을 가지고 로지스틱 회귀를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 코드 구현\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "data = torch.from_numpy(df[cols].values).float()\n",
    "\n",
    "data.shape\n",
    "# Split x and y.\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀와 동일한 방식으로 텐서 x와 텐서 y를 가져온다.\n",
    "# 학습에 필요한 설정값을 정해준다.\n",
    "\n",
    "# Define configurations\n",
    "n_epochs = 200000\n",
    "learning_rate = 1e-2\n",
    "print_interval=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 모델을 준비한다.\n",
    "# 선형 회귀에서는 선형 계층 하나만 필요했지만, 이번엔 시그모이드 함수도 모델에 포함한다.\n",
    "# 즉, nn.Module을 상속받아 클래스를 정의하고 내부에 필요한 계층들을 소유하도록 한다.\n",
    "\n",
    "# nn.Module을 상속받은 자식 클래스를 정의할 때는 보통 두 개의 함수(메서드)를 오버라이드 한다.\n",
    "# 또한, __init__ 함수를 통해 모델을 구성하는 데 필요한 내부 모듈을 미리 선언해 둔다.\n",
    "# forward 함수는 미리 선언된 내부 모듈을 활용하여 계산을 수행한다.\n",
    "\n",
    "# Define costum model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.act = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_dim)\n",
    "        y = self.act(self.linear(x))\n",
    "        # |y| = (batch_size, output_dim)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 정의한 나만의 로지스특 회귀 모델 클래스를 생성하고 BCE 손실 함수와 옵티마이저도 준비한다.\n",
    "# 선형 회귀와 마찬가지로 모델의 입력 크기는 텐서 x의 마지막 차원의 크기가 되고\n",
    "# 출력 크기는 텐서 y의 마지막 차원 크기가 된다.\n",
    "\n",
    "model = MyModel(input_dim=x.size(-1), output_dim=y.size(-1))\n",
    "crit = nn.BCELoss() # Define BCELoss instead of MSELoss\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 준비는 끝\n",
    "# 선형 회귀와 똑같은 코드로 학습을 진행시킨다.\n",
    "for i in range(n_epochs):\n",
    "    y_hat = model(x)\n",
    "    loss = crit(y_hat, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    if(i + 1) % print_interval == 0:\n",
    "        print(\"Epoch %d : loss = %.4e\" % (i + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "# 지금은 분류 문제이므로 예측 결과에 대한 정확도 평가가 가능하다.\n",
    "# 마지막 모델을 통과하여 얻은 y_hat과 y를 비교하여 정확도를 계산한다.\n",
    "correct_cnt = (y == (y_hat > .5)).sum()\n",
    "total_cnt = float(y.size(0))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (correct_cnt / total_cnt)) # Accuracy: 0.9649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측된 결괏값의 분포도 살펴볼 수 있다.\n",
    "df = pd.DataFrame(torch.cat([y, y_hat], dim=1).detach().numpy(), columns=[\"y\", \"y_hat\"])\n",
    "\n",
    "sns.histplot(df, x=\"y_hat\", hue=\"y\", bins=50, stat=\"probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 분포가 양 극단으로 완벽하게 치우쳐져 있다면, 모델이 매우 예측을 잘하고 있다고 판단할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
